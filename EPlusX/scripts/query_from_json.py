#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import json, re
import numpy as np
import pandas as pd
import hnswlib
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
from config import paths

paths.ensure_dirs()

# OpenAI ì´ˆê¸°í™”
load_dotenv()
client = OpenAI()

EMBED_MODEL = "text-embedding-3-large"
GPT_MODEL   = "gpt-4o"

# â”€â”€â”€ 1) HNSW ì¸ë±ìŠ¤ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
print("[+] HNSW ì¸ë±ìŠ¤ ë¡œë“œ:", paths.INDEX_PATH)
if not paths.INDEX_PATH.exists():
    raise FileNotFoundError(f"âŒ ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {paths.INDEX_PATH}")
p = hnswlib.Index(space="l2", dim=1)
p.load_index(str(paths.INDEX_PATH))
with open(paths.IDMAP_PATH, "r", encoding="utf-8") as f:
    id_map = json.load(f)

# â”€â”€â”€ 2) ì„ë² ë”©ëœ ì²­í¬ ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
id2text = {}
for fn in paths.EMBED_DIR.iterdir():
    if fn.suffix == ".jsonl":
        for line in fn.read_text(encoding="utf-8").splitlines():
            rec = json.loads(line)
            id2text[rec["id"]] = rec["text"]

# â”€â”€â”€ 3) ì—‘ì…€ â†’ dict â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def excel_to_dict(path: Path) -> dict:
    df = pd.read_excel(path)
    return {
        str(r["í•­ëª©"]).strip(): str(r["ì˜ˆì‹œ ì…ë ¥ê°’"]).strip()
        for _, r in df.iterrows()
    }

# â”€â”€â”€ 4) RAG ê²€ìƒ‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_chunks(query: str, top_k: int = 8) -> list[str]:
    qvec = client.embeddings.create(model=EMBED_MODEL, input=query).data[0].embedding
    labels, _ = p.knn_query(np.array([qvec], dtype="float32"), k=top_k)
    return [ id2text.get(id_map[idx], "") for idx in labels[0] ]

# â”€â”€â”€ 5) Prompt ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_prompt(info: dict) -> str:
    header = (
        "ë‹¤ìŒì€ ê±´ë¬¼ ê¸°ë³¸ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ EnergyPlusì— í•„ìš”í•œ ëª¨ë“  IDF ê°ì²´ë¥¼\n"
        "JSON ë¦¬ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œ **ë¹ ì§ì—†ì´** ì œì•ˆí•´ì£¼ì„¸ìš”.\n\n"
        "ğŸ“Œ **source ë¶„ë¥˜ ê¸°ì¤€** ğŸ“Œ\n"
        "- **Revit**: Revit ëª¨ë¸(Geometry, Zone, Surface, Construction, Material ë“±)ì—ì„œ ìë™ ìƒì„± ê°€ëŠ¥í•œ ê°ì²´\n"
        "- **Web**: Revitì— ì—†ëŠ”, ìˆ˜ì‘ì—…ìœ¼ë¡œ ì¶”ê°€í•´ì•¼ í•˜ëŠ” Simulation-control, Schedule, Output ë“± ê°ì²´\n\n"
        "ğŸ”§ **ì¶œë ¥ ìŠ¤í™** ğŸ”§\n"
        "ê° ê°ì²´ë§ˆë‹¤ ë‹¤ìŒ ì†ì„±ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:\n"
        "1. idf_class (string)\n"
        "2. reason   (string)\n"
        "3. fields   (array of objects):\n"
        "      [ {\"name\":string, \"description\":string, \"default\":string}, ... ]\n"
        "4. source   (\"Revit\" ë˜ëŠ” \"Web\")\n\n"
        "ğŸ“ **ì˜ˆì‹œ**\n"
        "```json\n"
        "[\n"
        "  {\n"
        "    \"idf_class\": \"Building\",\n"
        "    \"reason\": \"ê±´ë¬¼ ê¸°ë³¸ ì •ë³´ ì •ì˜\",\n"
        "    \"fields\": [\n"
        "      {\"name\":\"Name\",\"description\":\"ê±´ë¬¼ ì´ë¦„\",\"default\":\"\"},\n"
        "      {\"name\":\"North Axis\",\"description\":\"ë¶ìª½ íšŒì „ê°\",\"default\":\"0\"}\n"
        "    ],\n"
        "    \"source\": \"Web\"\n"
        "  }\n"
        "]\n"
        "```\n\n"
        "ì…ë ¥ ì •ë³´:\n"
    )
    body = "\n".join(f"{k}: {v}" for k, v in info.items())
    return header + body

# â”€â”€â”€ 6) GPT í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_gpt(prompt: str, docs: list[str]) -> str:
    messages = [
        {"role": "system",  "content": "You are an EnergyPlus IDF expert."},
        {"role": "system",  "content": "ì°¸ê³  ë¬¸ì„œ:\n\n" + "\n\n".join(docs)},
        {"role": "user",    "content": prompt}
    ]
    resp = client.chat.completions.create(model=GPT_MODEL, messages=messages)
    return resp.choices[0].message.content

# â”€â”€â”€ 7) ì‘ë‹µì—ì„œ JSONë§Œ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def extract_json(text: str) -> str:
    m = re.search(r"```json\s*(.*?)```", text, re.DOTALL)
    payload = m.group(1) if m else text
    # C++ ìŠ¤íƒ€ì¼ ì£¼ì„ ì œê±°
    payload = re.sub(r"//.*", "", payload)
    return payload.strip()

# â”€â”€â”€ 8) ì—‘ì…€ í…œí”Œë¦¿ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def save_to_excel(objs: list[dict], out: Path=paths.TEMPLATE_XLSX):
    rev, web = [], []
    for o in objs:
        for f in o.get("fields", []):
            row = {
                "IDF ê°ì²´":      o.get("idf_class",""),
                "í•„ìš” ì´ìœ ":      o.get("reason",""),
                "í•„ë“œ ì´ë¦„":      f.get("name",""),
                "í•„ë“œ ì„¤ëª…":      f.get("description",""),
                "ê°’ ì…ë ¥(ê¸°ë³¸)": f.get("default","")
            }
            if o.get("source","").lower() == "revit":
                rev.append(row)
            else:
                web.append(row)

    with pd.ExcelWriter(out, engine="openpyxl") as w:
        pd.DataFrame(rev).to_excel(w, sheet_name="Revit", index=False)
        pd.DataFrame(web).to_excel(w, sheet_name="Web", index=False)

    print(f"[ğŸ‰] ì—‘ì…€ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ â†’ {out}")

# â”€â”€â”€ 9) main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    info    = excel_to_dict(paths.INPUT_EXCEL)
    prompt  = build_prompt(info)
    docs    = search_chunks(prompt, top_k=8)
    print(f"[ğŸ”] ê²€ìƒ‰ëœ ë¬¸ì„œ ê°œìˆ˜: {len(docs)}")
    answer  = ask_gpt(prompt, docs)

    try:
        payload = extract_json(answer)
        objs    = json.loads(payload)
        save_to_excel(objs)
    except Exception as e:
        print("âš ï¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)
        print("â–¶ï¸ GPT ì‘ë‹µ ì›ë³¸:\n", answer)

if __name__ == "__main__":
    main()
